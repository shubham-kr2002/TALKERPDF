import os
import io
import base64
import fitz  # PyMuPDF
import chromadb
from sentence_transformers import SentenceTransformer
from PIL import Image
from openai import OpenAI
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from config.settings import CHROMA_DB_PATH, DATA_DOCS_PATH

load_dotenv()

# Initialize ChromaDB client
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)

# Initialize embedding model (small, free, runs locally)
embedding_model = SentenceTransformer('all-mpnet-base-v2')

# Initialize Groq client for vision tasks
groq_client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=os.getenv("GROQ_API_KEY"),
)

# Setup image storage directory
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
IMAGE_STORAGE_PATH = os.path.join(BASE_DIR, "app", "static", "images")
os.makedirs(IMAGE_STORAGE_PATH, exist_ok=True)

def is_logo_or_icon(width, height):
    """
    HEURISTIC: If an image is too small or has weird aspect ratio, 
    it's likely a logo, footer line, or decoration. We ignore it to save money.
    
    Args:
        width: Image width in pixels
        height: Image height in pixels
    
    Returns:
        True if image should be ignored, False if it should be processed
    """
    # Reject anything smaller than 300x300 pixels (logos, icons, small decorations)
    if width < 300 or height < 300:
        return True
    
    # Reject weird aspect ratios (like footer lines or narrow banners)
    aspect_ratio = width / height
    if aspect_ratio > 5 or aspect_ratio < 0.2:
        return True
        
    return False


def optimize_image(image):
    """
    Optimize image for Llama-4 Scout vision API.
    Resizes to 512x512 to save tokens and bandwidth.
    
    Args:
        image: PIL Image object
    
    Returns:
        Base64-encoded JPEG string
    """
    # Resize strictly to 512px to save tokens
    max_size = 512
    image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
    
    # Convert to RGB (remove alpha channel if present)
    if image.mode in ('RGBA', 'LA', 'P'):
        background = Image.new('RGB', image.size, (255, 255, 255))
        if image.mode == 'P':
            image = image.convert('RGBA')
        background.paste(image, mask=image.split()[-1] if image.mode in ('RGBA', 'LA') else None)
        image = background
    elif image.mode != 'RGB':
        image = image.convert('RGB')
    
    # Save as JPEG with quality=60 to reduce size
    buffer = io.BytesIO()
    image.save(buffer, format='JPEG', quality=60, optimize=True)
    buffer.seek(0)
    
    # Encode to base64
    base64_image = base64.b64encode(buffer.read()).decode('utf-8')
    return base64_image


def extract_images_from_page(doc, page, pdf_name, page_num):
    """
    Extracts ONLY relevant images (charts/diagrams) from the PDF page object.
    Filters out logos, icons, and decorative elements using size heuristics.
    Saves valid images to local storage for UI display.
    
    Args:
        doc: PyMuPDF document object
        page: PyMuPDF page object
        pdf_name: Name of the PDF file (for unique filenames)
        page_num: Page number (for unique filenames)
    
    Returns:
        List of dicts with {'base64': str, 'file_path': str} for valid charts/diagrams
    """
    image_list = page.get_images()
    valid_images = []

    for img_index, img in enumerate(image_list):
        xref = img[0]
        
        try:
            # Extract image from PDF internal structure (fast, no rendering!)
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]
            
            # Load as PIL Image to check dimensions
            pil_image = Image.open(io.BytesIO(image_bytes))
            w, h = pil_image.size
            
            # Apply "Logo Filter" - skip small images and weird aspect ratios
            if is_logo_or_icon(w, h):
                print(f"    ‚äó Skipping small image {w}x{h} (Logo/Icon)")
                continue  # Skip this image -> Save API cost!
            
            print(f"    ‚úì Valid chart found: {w}x{h} pixels")
            
            # Generate unique filename for this image
            pdf_basename = os.path.splitext(pdf_name)[0]  # Remove .pdf extension
            filename = f"{pdf_basename}_page_{page_num + 1}_img_{img_index + 1}.png"
            file_path = os.path.join(IMAGE_STORAGE_PATH, filename)
            
            # Save the original high-quality image for UI display
            pil_image_copy = pil_image.copy()
            if pil_image_copy.mode in ('RGBA', 'LA', 'P'):
                background = Image.new('RGB', pil_image_copy.size, (255, 255, 255))
                if pil_image_copy.mode == 'P':
                    pil_image_copy = pil_image_copy.convert('RGBA')
                background.paste(pil_image_copy, mask=pil_image_copy.split()[-1] if pil_image_copy.mode in ('RGBA', 'LA') else None)
                pil_image_copy = background
            elif pil_image_copy.mode != 'RGB':
                pil_image_copy = pil_image_copy.convert('RGB')
            
            pil_image_copy.save(file_path, 'PNG', quality=95)
            print(f"      üíæ Saved to: {filename}")
            
            # Optimize image for API (smaller, compressed)
            optimized_b64 = optimize_image(pil_image)
            
            # Return both base64 (for AI) and file path (for UI)
            valid_images.append({
                'base64': optimized_b64,
                'file_path': file_path,
                'filename': filename
            })
            
        except Exception as e:
            print(f"    ‚úó Image extraction error: {e}")
            continue

    return valid_images


def analyze_image(base64_img):
    """
    Use Llama-4 Scout to analyze charts/tables in images.
    THREAD-SAFE: Only works with base64 strings, no fitz objects.
    
    Args:
        base64_img: Base64-encoded image string
    
    Returns:
        Transcribed text/markdown from the image
    """
    try:
        response = groq_client.chat.completions.create(
            model="meta-llama/llama-4-scout-17b-16e-instruct",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Transcribe this table/chart into Markdown. If it is a chart, summarize the key trends. Do not include introductory text."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_img}"
                            }
                        }
                    ]
                }
            ],
            temperature=0.1,
            max_tokens=1024
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"      ‚úó API Error: {e}")
        return ""


def process_vision_task(task_data):
    """
    THREAD-SAFE: Process a single vision task (image analysis).
    This function is called by ThreadPoolExecutor workers.
    
    Args:
        task_data: Dict with {'page': int, 'img_idx': int, 'base64_img': str, 'file_path': str}
    
    Returns:
        Dict with {'page': int, 'img_idx': int, 'description': str, 'file_path': str, 'success': bool}
    """
    page_num = task_data['page']
    img_idx = task_data['img_idx']
    base64_img = task_data['base64_img']
    file_path = task_data['file_path']
    
    try:
        description = analyze_image(base64_img)
        success = bool(description)
        return {
            'page': page_num,
            'img_idx': img_idx,
            'description': description,
            'file_path': file_path,
            'success': success
        }
    except Exception as e:
        print(f"      ‚úó Thread error processing page {page_num + 1}, image {img_idx + 1}: {e}")
        return {
            'page': page_num,
            'img_idx': img_idx,
            'description': "",
            'file_path': file_path,
            'success': False
        }


def extract_text_from_pdf(pdf_path):        description = analyze_image(base64_img)
        success = bool(description)
        return {
            'page': page_num,
            'img_idx': img_idx,
            'description': description,
            'success': success
        }
    except Exception as e:
        print(f"      ‚úó Thread error processing page {page_num + 1}, image {img_idx + 1}: {e}")
        return {
            'page': page_num,
            'img_idx': img_idx,
            'description': "",
            'success': False
        }


def extract_text_from_pdf(pdf_path):
    """
    Extract text from a PDF file using PyMuPDF.
    Returns a list of tuples (page_number, text) for each page.
    """
    pages_text = []
    try:
        doc = fitz.open(pdf_path)
        for page_num, page in enumerate(doc):
            text = page.get_text()
            pages_text.append((page_num, text))
        doc.close()
    except Exception as e:
        print(f"Error extracting text from {pdf_path}: {e}")
    return pages_text


def sliding_window_chunker(text, chunk_size=500, overlap=100):
    """
    Split text into chunks using a sliding window approach.
    
    Args:
        text: The text to chunk
        chunk_size: Size of each chunk in characters
        overlap: Number of overlapping characters between chunks
    
    Returns:
        List of text chunks
    """
    chunks = []
    start = 0
    text_length = len(text)
    
    while start < text_length:
        end = start + chunk_size
        chunk = text[start:end]
        
        # Only add non-empty chunks
        if chunk.strip():
            chunks.append(chunk)
        
        # Move the window forward
        start += chunk_size - overlap
    
    return chunks


def get_existing_documents(collection):
    """Get list of already ingested document names from collection metadata."""
    try:
        # Get all items from collection
        all_items = collection.get()
        if all_items and all_items['metadatas']:
            # Extract unique source names
            existing_docs = set(meta['source'] for meta in all_items['metadatas'])
            return existing_docs
        return set()
    except Exception as e:
        print(f"Error checking existing documents: {e}")
        return set()


def ingest_pdfs(uploaded_files):
    """
    Process uploaded PDF files and store in ChromaDB.
    Handles text, charts, and tables using multimodal Llama-4 Scout.
    Uses Two-Phase Architecture for parallel processing.
    Prevents duplicate ingestion of already processed documents.
    """
    # Get or create collection
    collection = chroma_client.get_or_create_collection(
        name="rag_docs",
        metadata={"description": "RAG document chunks"}
    )
    
    # Check for existing documents
    existing_docs = get_existing_documents(collection)
    print(f"Already ingested documents: {existing_docs}")
    
    ingested_count = 0
    skipped_count = 0
    
    for uploaded_file in uploaded_files:
        filename = uploaded_file.name
        
        # Skip if already ingested
        if filename in existing_docs:
            print(f"Skipping {filename} - already ingested")
            skipped_count += 1
            continue
        
        # Save uploaded file to data/docs
        pdf_path = os.path.join(DATA_DOCS_PATH, filename)
        with open(pdf_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # Extract text from PDF (now returns list of (page_num, text) tuples)
        pages_text = extract_text_from_pdf(pdf_path)
        
        if not pages_text:
            print(f"Warning: No pages extracted from {filename}")
            continue
        
        # ============================================================
        # PHASE 1: EXTRACTION (Main Thread - Safe PDF Operations)
        # ============================================================
        print(f"\n{'='*60}")
        print(f"PHASE 1: Extracting text and images from {filename}")
        print(f"{'='*60}")
        
        pending_tasks = []  # List of vision tasks to process in parallel
        page_data = []  # Store page info for assembly later
        
        # Open PDF with PyMuPDF (ONLY in main thread!)
        doc = fitz.open(pdf_path)
        
        for page_num, page_text in pages_text:
            page = doc[page_num]
            
            print(f"  Page {page_num + 1}: Extracting ({len(page_text.strip())} chars of text)")
            
            # Extract relevant images directly from PDF structure (with file paths)
            valid_images = extract_images_from_page(doc, page, filename, page_num)
            
            # Store page data (text + placeholder for images)
            page_info = {
                'page_num': page_num,
                'text': page_text,
                'images': [],  # Will be populated with descriptions later
                'image_count': len(valid_images)
            }
            
            # Queue vision tasks for parallel processing
            if valid_images:
                print(f"    ‚Üí Queued {len(valid_images)} charts for parallel processing")
                for img_idx, img_data in enumerate(valid_images):
                    task = {
                        'page': page_num,
                        'img_idx': img_idx,
                        'base64_img': img_data['base64'],
                        'file_path': img_data['file_path']
                    }
                    pending_tasks.append(task)
            
            page_data.append(page_info)
        # Open PDF with PyMuPDF (ONLY in main thread!)
        doc = fitz.open(pdf_path)
        
        for page_num, page_text in pages_text:
            page = doc[page_num]
            
            print(f"  Page {page_num + 1}: Extracting ({len(page_text.strip())} chars of text)")
            
            # Extract relevant images directly from PDF structure
            valid_images = extract_images_from_page(doc, page)
            
            # Store page data (text + placeholder for images)
            page_info = {
                'page_num': page_num,
                'text': page_text,
                'images': [],  # Will be populated with descriptions later
                'image_count': len(valid_images)
            }
            
            # Queue vision tasks for parallel processing
            if valid_images:
                print(f"    ‚Üí Queued {len(valid_images)} charts for parallel processing")
                for img_idx, base64_img in enumerate(valid_images):
                    task = {
                        'page': page_num,
                        'img_idx': img_idx,
                        'base64_img': base64_img
                    }
                    pending_tasks.append(task)
            
            page_data.append(page_info)
        
        # Close PDF document (BEFORE threading!)
        doc.close()
        print(f"\n  ‚úì Extraction complete: {len(page_data)} pages, {len(pending_tasks)} images queued")
        
        # ============================================================
        # PHASE 2: PARALLEL PROCESSING (Vision API Calls)
        # ============================================================
        if pending_tasks:
            print(f"\n{'='*60}")
            print(f"PHASE 2: Processing {len(pending_tasks)} images in parallel (max 4 workers)")
            print(f"{'='*60}")
            
            vision_results = {}  # Store results by (page, img_idx)
            
            with ThreadPoolExecutor(max_workers=4) as executor:
                # Submit all tasks
                future_to_task = {
                    executor.submit(process_vision_task, task): task 
                    for task in pending_tasks
        for page_info in page_data:
            page_num = page_info['page_num']
            page_text = page_info['text']
            image_count = page_info['image_count']
            
            # Collect vision descriptions and image paths for this page
            visual_summaries = []
            image_paths = []
            if image_count > 0:
                for img_idx in range(image_count):
                    key = (page_num, img_idx)
                    if key in vision_results and vision_results[key]['success']:
                        description = vision_results[key]['description']
                        file_path = vision_results[key]['file_path']
                        visual_summaries.append(f"[Chart/Diagram {img_idx + 1}]: {description}")
                        image_paths.append(file_path)
            
            # Merge text + visual summaries
            combined_content = page_text
            if visual_summaries:
                combined_content += "\n\n" + "\n\n".join(visual_summaries)
            
            # Chunk the combined content
            if combined_content.strip():
                chunks = sliding_window_chunker(combined_content, chunk_size=500, overlap=100)
                for chunk_idx, chunk in enumerate(chunks):
                    all_chunks.append(chunk)
                    chunk_type = "text_with_visuals" if visual_summaries else "text"
                    
                    # Build metadata with image paths if available
                    metadata = {
                        "source": filename,
                        "page": page_num + 1,
                        "type": chunk_type,
                        "chunk_id": f"page_{page_num + 1}_chunk_{chunk_idx}",
                        "has_visuals": len(visual_summaries) > 0
                    }
                    
                    # Add image paths to metadata for UI display
                    if image_paths:
                        metadata["image_paths"] = image_paths
                    
                    all_metadatas.append(metadata)
                
                status = f"with {len(visual_summaries)} visuals" if visual_summaries else "text-only"
                print(f"  Page {page_num + 1}: {len(chunks)} chunks ({status})")
            image_count = page_info['image_count']
            
            # Collect vision descriptions for this page
            visual_summaries = []
            if image_count > 0:
                for img_idx in range(image_count):
                    key = (page_num, img_idx)
                    if key in vision_results and vision_results[key]['success']:
                        description = vision_results[key]['description']
                        visual_summaries.append(f"[Chart/Diagram {img_idx + 1}]: {description}")
            
            # Merge text + visual summaries
            combined_content = page_text
            if visual_summaries:
                combined_content += "\n\n" + "\n\n".join(visual_summaries)
            
            # Chunk the combined content
            if combined_content.strip():
                chunks = sliding_window_chunker(combined_content, chunk_size=500, overlap=100)
                for chunk_idx, chunk in enumerate(chunks):
                    all_chunks.append(chunk)
                    chunk_type = "text_with_visuals" if visual_summaries else "text"
                    all_metadatas.append({
                        "source": filename,
                        "page": page_num + 1,
                        "type": chunk_type,
                        "chunk_id": f"page_{page_num + 1}_chunk_{chunk_idx}",
                        "has_visuals": len(visual_summaries) > 0
                    })
                
                status = f"with {len(visual_summaries)} visuals" if visual_summaries else "text-only"
                print(f"  Page {page_num + 1}: {len(chunks)} chunks ({status})")
        
        print(f"\n  ‚úì Assembly complete: {len(all_chunks)} total chunks")
        
        if not all_chunks:
            print(f"  ‚ö† Warning: No chunks generated from {filename}")
            continue
        
        # ============================================================
        # PHASE 4: BATCH ENCODING & STORAGE (ChromaDB)
        # ============================================================
        print(f"\n{'='*60}")
        print(f"PHASE 4: Encoding and storing in ChromaDB")
        print(f"{'='*60}")
        
        # BATCH ENCODING: Process chunks in batches for 3-5x speedup
        batch_size = 32
        total_batches = (len(all_chunks) + batch_size - 1) // batch_size
        
        for batch_num, batch_start in enumerate(range(0, len(all_chunks), batch_size), 1):
            batch_end = min(batch_start + batch_size, len(all_chunks))
            batch_chunks = all_chunks[batch_start:batch_end]
            batch_metas = all_metadatas[batch_start:batch_end]
            
            # Generate embeddings for entire batch at once (much faster!)
            batch_embeddings = embedding_model.encode(batch_chunks, show_progress_bar=False)
            
            # Prepare batch IDs for ChromaDB
            batch_ids = [
                f"{filename}_{meta['chunk_id']}" 
                for meta in batch_metas
            ]
            
            # Add entire batch to ChromaDB at once
            collection.add(
                embeddings=batch_embeddings.tolist(),
                documents=batch_chunks,
                metadatas=batch_metas,
                ids=batch_ids
            )
            
            print(f"  Batch {batch_num}/{total_batches}: Stored {len(batch_chunks)} chunks")
        
        # Count chunks by type for reporting
        text_chunks = sum(1 for m in all_metadatas if m['type'] == 'text')
        visual_chunks = sum(1 for m in all_metadatas if m['type'] == 'text_with_visuals')
        
        print(f"\n{'='*60}")
        print(f"‚úì Successfully ingested {filename}")
        print(f"{'='*60}")
        print(f"  üìÑ Text-only chunks: {text_chunks}")
        print(f"  üñºÔ∏è  Chunks with visuals: {visual_chunks}")
        print(f"  üìä Total chunks: {len(all_chunks)}")
        print(f"{'='*60}\n")
        ingested_count += 1
    
    print(f"\n{'='*60}")
    print(f"Ingestion complete: {ingested_count} new documents, {skipped_count} skipped")
    print(f"{'='*60}")
    return True
